# Alpha质量改进指南

## 🔍 问题诊断

### 当前状况分析

根据你的运行结果：
- ✅ 模型训练完成（词汇表91个token）
- ✅ 成功生成5000个候选Alpha
- ✅ 提交300个Alpha回测
- ❌ **预测分数偏低**：0.36-0.41（期望>1.0）
- ❌ **实际Sharpe/Fitness未达标**：低于1.25/1.0

### 问题根源

#### 1. **训练数据质量问题** ⭐⭐⭐⭐⭐（最关键）

**症状**：
- 词汇表只有91个token（正常应该500-1000+）
- 说明训练数据量很少或表达式过于简单

**原因**：
- 训练数据中高质量Alpha比例低
- 数据量不足（可能只有几百条）
- 表达式复杂度不够

**影响**：
- 模型没见过足够多的高质量模式
- 预测能力严重受限

#### 2. **模型预测范围问题** ⭐⭐⭐⭐

**症状**：
- 预测分数范围：0.36-0.41
- 实际Sharpe范围：-2.0 到 3.0+
- 量级不匹配

**原因**：
- 模型学习的是**相对排序**，不是绝对值预测
- 训练时标准化了目标变量
- 模型输出需要重新映射到真实范围

**解决方案**：
- 关注排序而非绝对值
- 预测Top 10%而非Top 50%

#### 3. **生成策略单一** ⭐⭐⭐

**症状**：
- 只使用了一阶工厂（first_order_factory）
- 缺少二阶组合、group操作、trade_when策略

**影响**：
- 生成的Alpha复杂度不够
- 难以产生高Sharpe的表达式

---

## 🚀 改进方案（按优先级排序）

### 方案1：收集更多高质量训练数据 ⭐⭐⭐⭐⭐

**立即执行（最重要）**

```python
# 在UI的"数据采集"页面设置：
开始日期: 01-01
结束日期: 12-31
最小数量: 2000
最大数量: 5000

# 重要：采集时筛选高质量数据
# 修改collector.py中的筛选条件
min_sharpe = 0.8  # 从0.5提高到0.8
min_fitness = 0.5  # 从0.3提高到0.5
```

**为什么重要**：
- 训练数据质量 = 模型上限
- 91个token说明数据太少
- 目标：词汇表达到800-1200个token

**预期效果**：
- 词汇表扩大10倍
- 模型见过更多高质量模式
- 预测准确度大幅提升

---

### 方案2：优化模型训练参数 ⭐⭐⭐⭐

**调整训练配置**

```python
# 在UI的"模型训练"页面设置：
训练轮数: 100（从30增加到100）
学习率: 5e-5（从1e-4降低，更稳定）
批次大小: 32（保持不变）

# 观察验证相关性
# 目标：验证相关性 > 0.4
# 如果验证相关性持续下降，提前停止
```

**关键指标**：
- 验证损失（Val Loss）：越低越好
- **验证相关性（Val Correlation）**：> 0.4为良好
- 训练损失不应远低于验证损失（避免过拟合）

---

### 方案3：分析预测vs实际相关性 ⭐⭐⭐⭐

**等待回测完成后执行**

1. **在"回测结果查询"页面**：
   - 设置最小Sharpe: 0.3（较低，获取更多数据）
   - 设置最小Fitness: 0.2
   - 点击"获取回测结果"

2. **分析预测质量**：
   ```python
   # 对比预测分数和实际Sharpe
   预测Top 100 中，实际Sharpe > 1.0的比例
   
   # 如果比例 > 30%：模型有效，继续优化
   # 如果比例 < 20%：需要重新采集数据和训练
   ```

3. **记录结果**：
   - 预测Top 100的实际Sharpe分布
   - 预测Top 300的实际Sharpe分布
   - 计算预测与实际的Spearman相关系数

---

### 方案4：改进Alpha生成策略 ⭐⭐⭐

**添加更复杂的表达式生成**

当前只用了一阶工厂，建议：

```python
# 1. 增加二阶Alpha生成
# 在原有Alpha基础上组合生成二阶

# 2. 添加group操作
group_neutralize()  # 行业中性化
group_rank()        # 行业内排名
group_zscore()      # 行业内标准化

# 3. 添加trade_when策略
# 事件驱动型Alpha
```

**实现方式**：
- 使用原有`machine_lib.py`中的二阶工厂
- 或等待后续系统更新

---

### 方案5：建立迭代优化循环 ⭐⭐⭐⭐⭐

**长期策略（最有效）**

```
第1轮：
1. 训练初始模型
2. 生成5000个 → 回测Top 300
3. 收集实际结果

第2轮：
4. 将回测结果加入训练数据
5. 重新训练模型（数据更新）
6. 再次生成 → 回测Top 300

第3轮：
7. 继续迭代
8. 每轮模型都会进步

预期：3-5轮后，高质量Alpha占比从10%提升到40-50%
```

**关键**：
- 每次回测后，将结果重新采集
- 累积高质量数据
- 模型持续学习

---

## 📊 立即行动清单

### 今天（第1步）✅

1. **等待当前回测完成**（约30分钟-2小时）
   - 已提交300个Alpha

2. **在"回测结果查询"获取实际指标**
   - 查看实际Sharpe和Fitness分布
   - 分析预测Top 100的实际表现

3. **评估模型效果**
   - 如果Top 100中有20-30个Sharpe>1.0：模型可用，继续优化
   - 如果Top 100中<10个Sharpe>1.0：需要重新采集数据

---

### 明天（第2步）

1. **重新采集高质量数据**
   ```
   数据采集页面：
   - 最小数量: 2000
   - 最大数量: 5000
   - 等待1-2小时完成
   ```

2. **重新训练模型**
   ```
   模型训练页面：
   - 训练轮数: 100
   - 学习率: 5e-5
   - 观察验证相关性
   ```

3. **重新生成和回测**
   ```
   生成页面：
   - 生成数量: 10000（加倍）
   - Top-K: 1000
   - 回测Top 500（增加回测量）
   ```

---

### 本周（第3步）

1. **分析第二轮结果**
   - 对比两轮的预测准确度
   - 是否有提升

2. **如果效果好，继续迭代**
   - 第三轮：更多数据 + 更长训练

3. **如果效果一般，尝试方案4**
   - 添加二阶Alpha生成
   - 增加表达式复杂度

---

## 💡 关键洞察

### 为什么预测分数低但可能有效？

模型预测的是**相对排序**，不是绝对值：

```
预测分数     实际Sharpe
0.406   →   1.8  (Top 1)
0.402   →   1.5  (Top 2)
0.398   →   1.2  (Top 3)
0.395   →   0.9  (Top 10)
0.359   →   0.2  (Top 500)
```

**只要排序对了，就是成功的！**

关键指标：**Spearman秩相关系数**
- > 0.3：模型有用
- > 0.5：模型很好
- > 0.7：模型优秀

---

## 🎯 成功标准

### 短期目标（1周内）

- ✅ 词汇表扩大到800+ token
- ✅ 验证相关性 > 0.4
- ✅ 预测Top 100中，30%以上Sharpe > 1.0

### 中期目标（2-4周）

- ✅ 通过3轮迭代优化
- ✅ 高质量Alpha占比提升到40%
- ✅ 找到10个可提交的Alpha（Sharpe>1.25）

### 长期目标（1-3个月）

- ✅ 建立持续迭代流程
- ✅ 实现二阶Alpha生成
- ✅ 累积50+个高质量Alpha库
- ✅ 预测Top 500中，50%以上Sharpe > 0.8

---

## 🛠️ 技术调优建议

### 数据层面

```python
# collector.py 中调整筛选条件
config.factory.min_sharpe = 0.8  # 提高标准
config.factory.min_fitness = 0.5

# 增加数据多样性
采集不同时间段的数据
采集不同策略类型的Alpha
```

### 模型层面

```python
# 如果数据量增加到3000+，可以尝试更大模型
config.transformer.d_model = 512  # 从256增加
config.transformer.num_layers = 8  # 从6增加
config.transformer.dropout = 0.2   # 增加dropout防止过拟合
```

### 训练层面

```python
# 使用早停策略
if val_correlation下降连续10个epoch:
    停止训练
    
# 使用学习率衰减
每20个epoch降低学习率
```

---

## 📞 问题诊断流程

遇到问题时，按此流程检查：

### 检查点1：数据质量
```
词汇表大小 < 500？  → 采集更多数据
高质量Alpha < 30%？ → 提高筛选标准
```

### 检查点2：训练效果
```
验证相关性 < 0.3？  → 增加训练轮数或调整学习率
训练损失远低于验证损失？ → 过拟合，增加dropout
```

### 检查点3：预测质量
```
预测Top 100中高质量 < 20%？ → 重新采集数据
预测与实际相关性 < 0.3？    → 模型需要重新设计
```

---

## 🎉 总结

**最关键的改进**：
1. 🥇 **收集2000-5000条高质量训练数据**（最重要！）
2. 🥈 **建立迭代优化循环**（长期有效）
3. 🥉 **分析预测vs实际相关性**（验证效果）

**记住**：
- AI模型的上限 = 训练数据的质量
- 相对排序 > 绝对值预测
- 持续迭代 > 一次完美

**下一步**：
1. 等待回测完成
2. 获取实际指标
3. 根据结果决定策略（重新采集数据 or 直接迭代）

---

**文档版本**: v1.0  
**创建日期**: 2025-10-27  
**适用版本**: Alpha Transformer System v1.0
